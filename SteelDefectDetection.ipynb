{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0IkOe8zwYtt",
        "outputId": "1db89bbb-c609-4035-d6c9-8a7d480c47f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         ImageId  ClassId\n",
            "0  0002cc93b.jpg      1.0\n",
            "1  0007a71bf.jpg      3.0\n",
            "2  000a4bcdd.jpg      1.0\n",
            "3  000f6bf48.jpg      4.0\n",
            "4  0014fce06.jpg      3.0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv(\"/content/train.csv\")\n",
        "print(train_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dominant_classes = train_df.groupby('ImageId')['ClassId'].agg(lambda x: x.value_counts().index[0] if len(x.value_counts()) > 0 else -1)\n",
        "\n"
      ],
      "metadata": {
        "id": "DW02hd5iwr9o"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n"
      ],
      "metadata": {
        "id": "tWRRjRaRwwHK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "class SteelDataset(Dataset):\n",
        "    def __init__(self, df, image_folder, transform=None):\n",
        "        self.df = df\n",
        "        self.image_folder = image_folder\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.df.iloc[idx]['ImageId']\n",
        "        label = self.df.iloc[idx]['ClassId'] - 1\n",
        "        img_path = os.path.join(self.image_folder, img_name)\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n"
      ],
      "metadata": {
        "id": "wualGtZaw5o0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "eXb7UvgUw7Ke"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataset = SteelDataset(train_df, \"../data/train_images/\", transform=transform)\n",
        "val_dataset = SteelDataset(val_df, \"../data/train_images/\", transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "03xo3MuexItA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, 4)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZD1I7lWnxMRk",
        "outputId": "0f456b8b-8ccc-451b-89b5-9b4ceca5018b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 151MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "test_image_folder = \"/content/\"\n",
        "test_image_name = \"3036d3834.jpg\"\n",
        "\n",
        "predictions = []\n",
        "\n",
        "\n",
        "img_path = os.path.join(test_image_folder, test_image_name)\n",
        "image = Image.open(img_path).convert(\"RGB\")\n",
        "image = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    output = model(image)\n",
        "    _, predicted = torch.max(output, 1)\n",
        "\n",
        "predictions.append((test_image_name, predicted.item() + 1))\n",
        "\n",
        "df = pd.DataFrame(predictions, columns=['ImageId', 'ClassId'])\n",
        "df.to_csv(\"submission.csv\", index=False)\n",
        "\n",
        "print(\"Predictions saved to submission.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61NJ77rWzbD0",
        "outputId": "d4b2df36-7777-4b51-eef1-a7199f5aba61"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved to submission.csv\n"
          ]
        }
      ]
    }
  ]
}